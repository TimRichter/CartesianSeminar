{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "coordinate-granny",
   "metadata": {},
   "source": [
    "### On Marc Granovetter's paper \"Threshold Models of Collective Behaviour\"\n",
    "\n",
    "Granovetter discusses a simple model of collective behaviour:\n",
    "\n",
    "Any person p in some given group P joins in to some *behaviour* (e.g. \"taking part in a riot\") at a given timestep t+1, if the proportion of people that already had joined in at time t exceeds p's *threshold* to do so. After joining in, p has to stick to it. Granovetter usually assumes that initially, i.e. at time t=0, no person takes part in the said behaviour.\n",
    "\n",
    "As time evolves, the proportion of people having joined in is not falling and thus finally stabilizes. Granovetter's main point is to show that occasionally very small variations in the distribution of the individual thresholds can lead to dramatically different final participation proportions. His first example might seem a little contrived: There are 100 people, the first has threshold 0, the second threshold 1/100, and so on, the nth person having threshold (n-1)/100. Clearly, each one, by joining in, will trigger the next, leading to total rebellion. If, however, e.g. the girl with threshold 1/100 was hesitant and increased her threshold a little, the first guy would just rampage alone.\n",
    "\n",
    "Later he discusses a more realistic example where thresholds are distributed according to (a discrete approximation of) some normal distribution with mean value 0.25. The final participation proportion (FPP) is then a function of the standard deviation of the distribution. Granovetter observes that at some point (he gives 0.12, our computation below sees it rather around 0.10) the FPP jumps from a very small value (~0.06) to almost 1.\n",
    "\n",
    "The plot below illustrates what happens: FPP is the smallest argument value at which the graph of the cumulative distribution function (CDF) of the threshold distribution crosses the graph of the identity function from left to right. For small standard deviations (sigma), the S-shape of the CDF is rather steep, it's graph goes below the identity on the left side of the mean value and there are three intersections with the identity. As sigma increases, the CDF flattens and above the critical point, it crosses the identity merely once.\n",
    "\n",
    "We discussed some aspects of Granovetter's paper in the [Potsdam Cartesian Seminar](https://timrichter.github.io/CartesianSeminar/) in Mai 2021.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "prescribed-attraction",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import ipywidgets as widgets\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "vocal-playlist",
   "metadata": {},
   "outputs": [],
   "source": [
    "def F(x,mu,sigma):\n",
    "    '''\n",
    "    This is the cumulative distribution function\n",
    "    of a normal distribution with mean mu and \n",
    "    standard derivation sigma, restricted to the\n",
    "    interval [0,1] as described in Granovetter.\n",
    "    '''\n",
    "    # compare https://en.wikipedia.org/wiki/Normal_distribution#Cumulative_distribution_function\n",
    "    return 0.5 * (1 + math.erf((x - mu)/(sigma * math.sqrt(math.pi))))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "proof-architect",
   "metadata": {},
   "source": [
    "We plot F and the identity function in the interval \\[0,1\\], enabling sigma and mu to be adjusted. \n",
    "\n",
    "An interesting observation: for mu >= 0.5, there is also some sigma where 2 of the three intersection points disappear, but here it is the lowest that remains, and thus no jumping of the FPP occurs. And if mu > 0.5, FPP will always be < 0.5, approaching 0.5 from below for increasing sigma."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "nuclear-cisco",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "60cfe9a6c048412d98eeba8f67f4d8db",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dc7a44397be74fbc81adb56a00f09222",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(FloatSlider(value=0.09, description='sigma', max=1.0, min=0.03, step=0.01), FloatSlider(…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib widget\n",
    "xs=np.arange(0,1,0.01)\n",
    "fig=plt.figure()\n",
    "ax=fig.add_axes([0,0,1,1])\n",
    "\n",
    "\n",
    "@widgets.interact(sigma=(0.03,1.0,0.01),mu=(0.1,0.6,0.05))\n",
    "def update(sigma=0.10,mu=0.25):# set up plot\n",
    "    ys=[F(x,mu,sigma) for x in xs]\n",
    "    [l.remove() for l in ax.lines]\n",
    "    ax.plot(xs,xs,color='blue')\n",
    "    ax.plot(xs,ys,color='red')\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
